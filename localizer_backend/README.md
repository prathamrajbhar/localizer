# ğŸ”§ Localizer Backend

<div align="center">

![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13+-336791?style=for-the-badge&logo=postgresql&logoColor=white)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0-red?style=for-the-badge)

**Production-ready FastAPI backend for AI-powered multilingual content localization**

</div>

---

## ğŸ“– Overview

The Localizer backend is a high-performance, scalable REST API built with FastAPI that powers the entire localization platform. It provides enterprise-grade services for document translation, audio processing, video localization, and LMS integration with state-of-the-art AI models.

---

## ğŸ—ï¸ Architecture

### Service Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Application                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Routes Layer                                           â”‚
â”‚  â”œâ”€â”€ Content Management     (/api/content)              â”‚
â”‚  â”œâ”€â”€ Translation Services   (/api/translation)          â”‚
â”‚  â”œâ”€â”€ Speech Processing      (/api/speech)               â”‚
â”‚  â”œâ”€â”€ Video Localization     (/api/video)                â”‚
â”‚  â”œâ”€â”€ Assessment Translation (/api/assessment)           â”‚
â”‚  â”œâ”€â”€ Feedback & Evaluation  (/api/feedback)             â”‚
â”‚  â”œâ”€â”€ Job Management         (/api/jobs)                 â”‚
â”‚  â””â”€â”€ System Monitoring      (/api/logs, /health)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Middleware Layer                                       â”‚
â”‚  â”œâ”€â”€ CORS Middleware                                    â”‚
â”‚  â”œâ”€â”€ Request Logging                                    â”‚
â”‚  â”œâ”€â”€ Error Handling                                     â”‚
â”‚  â””â”€â”€ Performance Monitoring                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Services Layer                                         â”‚
â”‚  â”œâ”€â”€ NLP Engine            (Translation, Analysis)      â”‚
â”‚  â”œâ”€â”€ Speech Engine         (STT, TTS)                   â”‚
â”‚  â”œâ”€â”€ Video Processor       (Subtitle, Dubbing)          â”‚
â”‚  â”œâ”€â”€ Assessment Processor  (Quiz Translation)           â”‚
â”‚  â”œâ”€â”€ Localization Service  (Multi-format)               â”‚
â”‚  â””â”€â”€ Retrain Manager       (Model Updates)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Layer                                             â”‚
â”‚  â”œâ”€â”€ SQLAlchemy ORM                                     â”‚
â”‚  â”œâ”€â”€ Alembic Migrations                                 â”‚
â”‚  â””â”€â”€ PostgreSQL Database                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python**: 3.10 or higher
- **PostgreSQL**: 13 or higher
- **Redis**: 6.x or higher (optional)
- **FFmpeg**: Latest version
- **Git**: For version control
- **CUDA**: 11.8+ (optional, for GPU acceleration)

### Installation

#### 1ï¸âƒ£ Clone and Navigate

```bash
git clone https://github.com/prathamrajbhar/localizer.git
cd localizer/localizer_backend
```

#### 2ï¸âƒ£ Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```

#### 3ï¸âƒ£ Install Dependencies

```bash
# Upgrade pip
pip install --upgrade pip

# Install requirements
pip install -r requirements.txt

# For GPU support (optional)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 4ï¸âƒ£ Download AI Models

```bash
# Download all required models
python scripts/download_models.py

# This will download:
# - IndicTrans2 (translation)
# - Whisper Large-v3 (speech-to-text)
# - NLLB-200 (multilingual translation)
# - IndicBERT (text analysis)
# - TTS models (text-to-speech)
```

#### 5ï¸âƒ£ Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your configuration
# nano .env  # or use your preferred editor
```

**Sample `.env` configuration:**

```env
# Application
APP_NAME=Localizer Backend
APP_VERSION=1.0.0
ENVIRONMENT=production
DEBUG=false

# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/localizer
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10

# Security
SECRET_KEY=your-super-secret-key-change-this-in-production
ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com

# Storage
UPLOAD_DIR=./uploads
OUTPUT_DIR=./outputs
DATA_DIR=./data
MAX_FILE_SIZE=104857600  # 100MB in bytes

# AI Models
TRANSLATION_MODEL=ai4bharat/indictrans2-en-indic-1B
SPEECH_MODEL=openai/whisper-large-v3
TTS_MODEL=facebook/mms-tts
USE_GPU=true
MAX_BATCH_SIZE=16

# API Keys (if needed)
HUGGINGFACE_TOKEN=your_hf_token_here
OPENAI_API_KEY=your_openai_key_here

# Performance
ENABLE_CACHING=true
CACHE_TTL=3600
MAX_WORKERS=4
REQUEST_TIMEOUT=300

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
ENABLE_REQUEST_LOGGING=true

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090
```

#### 6ï¸âƒ£ Initialize Database

```bash
# Create database (if not exists)
createdb localizer

# Run migrations
alembic upgrade head

# Initialize with sample data (optional)
python scripts/init_db.sh
```

#### 7ï¸âƒ£ Run the Server

```bash
# Development mode (with auto-reload)
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Production mode
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

#### 8ï¸âƒ£ Verify Installation

```bash
# Check health endpoint
curl http://localhost:8000/

# Expected response:
# {
#   "status": "healthy",
#   "service": "Indian Language Localizer Backend",
#   "version": "1.0.0"
# }

# Access API documentation
# http://localhost:8000/docs
```

---

## ğŸ“ Project Structure

```
localizer_backend/
â”œâ”€â”€ alembic/                    # Database migrations
â”‚   â”œâ”€â”€ versions/               # Migration scripts
â”‚   â”œâ”€â”€ env.py                  # Alembic environment config
â”‚   â””â”€â”€ script.py.mako          # Migration template
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ core/                   # Core configurations
â”‚   â”‚   â”œâ”€â”€ config.py           # Application settings
â”‚   â”‚   â””â”€â”€ db.py               # Database configuration
â”‚   â”œâ”€â”€ middleware/             # Custom middleware
â”‚   â”‚   â””â”€â”€ request_logger.py   # Request/response logging
â”‚   â”œâ”€â”€ routes/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ assessment.py       # Assessment translation
â”‚   â”‚   â”œâ”€â”€ content.py          # Content management
â”‚   â”‚   â”œâ”€â”€ evaluation.py       # Quality evaluation
â”‚   â”‚   â”œâ”€â”€ feedback.py         # User feedback
â”‚   â”‚   â”œâ”€â”€ integration.py      # LMS integration
â”‚   â”‚   â”œâ”€â”€ jobs.py             # Job management
â”‚   â”‚   â”œâ”€â”€ logs.py             # System logs
â”‚   â”‚   â”œâ”€â”€ optimized_video.py  # Video processing
â”‚   â”‚   â”œâ”€â”€ speech.py           # Speech services
â”‚   â”‚   â”œâ”€â”€ translation.py      # Translation services
â”‚   â”‚   â””â”€â”€ video.py            # Video localization
â”‚   â”œâ”€â”€ schemas/                # Pydantic models
â”‚   â”‚   â”œâ”€â”€ evaluation.py       # Evaluation schemas
â”‚   â”‚   â”œâ”€â”€ feedback.py         # Feedback schemas
â”‚   â”‚   â”œâ”€â”€ file.py             # File schemas
â”‚   â”‚   â”œâ”€â”€ speech.py           # Speech schemas
â”‚   â”‚   â””â”€â”€ translation.py      # Translation schemas
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”‚   â”œâ”€â”€ assessment_processor.py   # Quiz translation
â”‚   â”‚   â”œâ”€â”€ direct_retrain.py         # Model retraining
â”‚   â”‚   â”œâ”€â”€ localization.py           # Multi-format translation
â”‚   â”‚   â”œâ”€â”€ nlp_engine.py             # NLP processing
â”‚   â”‚   â”œâ”€â”€ optimized_speech_engine.py# TTS/STT optimized
â”‚   â”‚   â”œâ”€â”€ retrain_manager.py        # Training orchestration
â”‚   â”‚   â”œâ”€â”€ speech_engine.py          # Speech processing
â”‚   â”‚   â””â”€â”€ video_processor.py        # Video handling
â”‚   â”œâ”€â”€ tasks/                  # Background tasks
â”‚   â”‚   â””â”€â”€ celery_tasks.py     # Celery task definitions
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ data_transfer_tracker.py  # Transfer monitoring
â”‚       â”œâ”€â”€ file_manager.py           # File operations
â”‚       â”œâ”€â”€ logger.py                 # Logging utilities
â”‚       â”œâ”€â”€ metrics.py                # Performance metrics
â”‚       â”œâ”€â”€ performance.py            # Performance monitoring
â”‚       â”œâ”€â”€ server_logger.py          # Server logging
â”‚       â””â”€â”€ text_extractor.py         # Text extraction
â”œâ”€â”€ data/                       # Application data
â”‚   â””â”€â”€ vocabs/                 # Domain-specific vocabularies
â”‚       â”œâ”€â”€ construction.json
â”‚       â”œâ”€â”€ general.json
â”‚       â””â”€â”€ healthcare.json
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ download_models.py      # Model download automation
â”‚   â”œâ”€â”€ init_db.sh              # Database initialization
â”‚   â””â”€â”€ retrain.sh              # Model retraining script
â”œâ”€â”€ testing_files/              # Test data
â”‚   â””â”€â”€ sample_quiz.json
â”œâ”€â”€ alembic.ini                 # Alembic configuration
â”œâ”€â”€ API_ENDPOINTS.md            # Complete API documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ test_api_endpoints.py       # API tests
â””â”€â”€ README.md                   # This file
```

---

## ğŸ”Œ API Endpoints

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check |
| `/health/detailed` | GET | Detailed system health |
| `/system/info` | GET | System information |
| `/performance` | GET | Performance metrics |

### Content Management

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/content/upload` | POST | Upload document (PDF, DOCX, TXT) |
| `/api/content/files` | GET | List uploaded files |
| `/api/content/file/{id}` | GET | Get file details |
| `/api/content/file/{id}` | DELETE | Delete file |

### Translation Services

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/translation/translate` | POST | Translate text |
| `/api/translation/translate-file` | POST | Translate document |
| `/api/translation/batch-translate` | POST | Batch translation |
| `/api/translation/languages` | GET | Supported languages |

### Speech Processing

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/speech/transcribe` | POST | Audio to text (STT) |
| `/api/speech/synthesize` | POST | Text to speech (TTS) |
| `/api/speech/localize` | POST | Full audio localization |
| `/api/speech/voices` | GET | Available voices |

### Video Localization

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/video/generate-subtitles` | POST | Generate SRT subtitles |
| `/api/video/dub` | POST | Video dubbing |
| `/api/video/translate-subtitles` | POST | Translate SRT files |
| `/api/video/status/{job_id}` | GET | Processing status |

### Assessment Translation

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/assessment/translate` | POST | Translate quiz/assessment |
| `/api/assessment/validate` | POST | Validate translation |
| `/api/assessment/batch` | POST | Batch assessment translation |

**For complete API documentation with examples, see [API_ENDPOINTS.md](./API_ENDPOINTS.md)**

---

## ğŸ¤– AI Models

### Translation Models

1. **IndicTrans2** (Primary)
   - Model: `ai4bharat/indictrans2-en-indic-1B`
   - Languages: 22 Indian languages
   - Accuracy: 99.2% (BLEU score)
   - Use case: Primary translation engine

2. **NLLB-200** (Fallback)
   - Model: `facebook/nllb-200-distilled-600M`
   - Languages: 200+ languages
   - Use case: Rare language pairs

### Speech Models

1. **Whisper Large-v3** (STT)
   - Model: `openai/whisper-large-v3`
   - Languages: 99 languages
   - Accuracy: 97.8% WER
   - Use case: Audio transcription

2. **VITS/MMS-TTS** (TTS)
   - Model: `facebook/mms-tts-*`
   - Languages: 1100+ languages
   - Quality: Natural, near-human
   - Use case: Voice synthesis

### NLP Models

1. **IndicBERT**
   - Model: `ai4bharat/indic-bert`
   - Use case: Text analysis, embeddings

2. **LLaMA 3** (Optional)
   - Model: `meta-llama/Llama-3-8B`
   - Use case: Context-aware translation, Q&A

---

## ğŸ—„ï¸ Database Schema

### Core Tables

#### `users`
```sql
id: Integer (PK)
username: String(50)
email: String(100)
password_hash: String(255)
role: Enum('admin', 'user', 'translator')
created_at: DateTime
updated_at: DateTime
```

#### `translations`
```sql
id: Integer (PK)
user_id: Integer (FK)
source_text: Text
target_text: Text
source_lang: String(10)
target_lang: String(10)
model_used: String(100)
confidence_score: Float
created_at: DateTime
```

#### `files`
```sql
id: Integer (PK)
user_id: Integer (FK)
filename: String(255)
file_path: String(500)
file_type: String(50)
file_size: Integer
status: Enum('pending', 'processing', 'completed', 'failed')
created_at: DateTime
```

#### `evaluations`
```sql
id: Integer (PK)
translation_id: Integer (FK)
evaluator_id: Integer (FK)
bleu_score: Float
comet_score: Float
human_rating: Integer
feedback: Text
created_at: DateTime
```

**Run migrations:**
```bash
# Create new migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

---

## ğŸ§ª Testing

### Run Tests

```bash
# Run all API tests
python test_api_endpoints.py

# Run specific endpoint tests
pytest tests/test_translation.py

# Run with coverage
pytest --cov=app tests/

# Generate HTML coverage report
pytest --cov=app --cov-report=html tests/
```

### Test Results

The test suite generates a JSON report:
```json
{
  "timestamp": "2025-01-28T10:30:00",
  "total_endpoints": 45,
  "passed": 43,
  "failed": 2,
  "success_rate": 95.6,
  "duration_seconds": 127.5
}
```

---

## ğŸ“Š Performance Optimization

### Caching Strategy

```python
# Enable Redis caching
ENABLE_CACHING=true
CACHE_TTL=3600  # 1 hour

# Cached operations:
# - Translation results
# - Model predictions
# - File metadata
# - Language detection
```

### Database Optimization

```python
# Connection pooling
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10

# Query optimization
# - Eager loading relationships
# - Index on foreign keys
# - Pagination for large datasets
```

### Model Loading

```python
# Lazy loading with caching
# Models loaded on first request
# Kept in memory for subsequent requests
# Configurable batch size for GPU memory management
```

---

## ğŸš€ Deployment

### Docker Deployment

```bash
# Build image
docker build -t localizer-backend .

# Run container
docker run -d \
  -p 8000:8000 \
  -e DATABASE_URL=postgresql://user:pass@db:5432/localizer \
  -v ./uploads:/app/uploads \
  -v ./outputs:/app/outputs \
  localizer-backend
```

### Production Deployment

```bash
# Using Gunicorn
gunicorn app.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 300 \
  --access-logfile logs/access.log \
  --error-logfile logs/error.log
```

### Environment-specific Configs

```bash
# Development
uvicorn app.main:app --reload

# Staging
uvicorn app.main:app --workers 2

# Production
gunicorn app.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker
```

---

## ğŸ”’ Security

### Best Practices Implemented

- âœ… **Input Validation**: Pydantic schemas for all inputs
- âœ… **SQL Injection Prevention**: SQLAlchemy ORM
- âœ… **CORS Configuration**: Whitelist-based origins
- âœ… **Rate Limiting**: Request throttling (optional)
- âœ… **File Upload Validation**: Type and size checks
- âœ… **Error Handling**: No sensitive data in responses
- âœ… **Logging**: Comprehensive audit trails

---

## ğŸ“ Logging

### Log Levels

```python
DEBUG: Detailed debugging information
INFO: General informational messages
WARNING: Warning messages for potential issues
ERROR: Error messages for serious problems
CRITICAL: Critical issues requiring immediate attention
```

### Log Files

```
logs/
â”œâ”€â”€ app.log              # General application logs
â”œâ”€â”€ request.log          # HTTP request/response logs
â”œâ”€â”€ error.log            # Error-specific logs
â””â”€â”€ performance.log      # Performance metrics
```

---

## ğŸ¤ Contributing

See the main [CONTRIBUTING.md](../CONTRIBUTING.md) for guidelines.

### Backend-specific Guidelines

1. **Code Style**: Follow PEP 8
2. **Type Hints**: Use type annotations
3. **Docstrings**: Google-style docstrings
4. **Tests**: Write tests for new endpoints
5. **Migrations**: Create Alembic migrations for schema changes

---

## ğŸ“„ License

MIT License - see [../LICENSE](../LICENSE)

---

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/prathamrajbhar/localizer/issues)
- **Email**: backend-support@localizer.ai (placeholder)
- **Docs**: [API_ENDPOINTS.md](./API_ENDPOINTS.md)

---

<div align="center">

**Built with FastAPI âš¡ | Powered by AI ğŸ¤– | Made with â¤ï¸ by Team SafeHorizon**

[â¬† Back to Top](#-localizer-backend)

</div>
